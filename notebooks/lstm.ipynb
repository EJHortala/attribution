{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../data/download/\"\n",
    "data_raw = \"../data/raw/\"\n",
    "\n",
    "\n",
    "def download_dataset(dataset_path):\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://go.criteois.com/criteo-research-attribution-dataset.zip\",\n",
    "        dataset_path + \"criteo_attribution_dataset.zip\",\n",
    "    )\n",
    "\n",
    "    zippath = dataset_path + \"criteo_attribution_dataset.zip\"\n",
    "    with zipfile.ZipFile(zippath, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(data_raw)\n",
    "\n",
    "\n",
    "if not os.path.exists(data_raw + \"criteo_attribution_dataset.tsv.gz\"):\n",
    "    print(\"Downloading dataset...\")\n",
    "    download_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_touchpoints, embedding_dim=None, hidden_size=None, out_features=None\n",
    "    ):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        embedding_dim = (\n",
    "            embedding_dim if embedding_dim else int(np.sqrt(num_touchpoints))\n",
    "        )\n",
    "        hidden_size = hidden_size if hidden_size else int(2 * num_touchpoints)\n",
    "        out_features = out_features if out_features else hidden_size\n",
    "\n",
    "        self.embeding = nn.Embedding(\n",
    "            num_embeddings=num_touchpoints, embedding_dim=embedding_dim\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim, hidden_size=hidden_size, num_layers=1\n",
    "        )\n",
    "        self.fc1 = nn.Linear(in_features=hidden_size, out_features=out_features)\n",
    "        self.fc2 = nn.Linear(out_features, 1, bias=False)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1, bias=False)\n",
    "        self.bias1 = nn.Parameter(torch.zeros(1, 1))\n",
    "        self.bias2 = nn.Parameter(torch.zeros(1, 1))\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.embeding(x[0])\n",
    "        h, _ = self.lstm(e.view(1, 1, -1))\n",
    "        v = self.tanh(self.fc1(h[0]))\n",
    "        a = self.softmax(self.fc2(v) - self.bias1 * x[1])\n",
    "        s = torch.dot(a, h)\n",
    "        p = self.sigmoid(self.relu(self.fc3(s)) + self.bias2)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cab1bcd757b22b674a73e32394e666864d7f76f5e492d5ca9bef603ab47d1ca"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
